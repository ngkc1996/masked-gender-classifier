{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/51/bafcff417cd857bc6684336320863b5e5af280530213ef8f534b6042cfe6/pandas-1.1.4-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5MB 16.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.2)\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 54.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.11.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.4 pytz-2020.4\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 29.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9MB 52.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 64.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.2)\n",
      "Installing collected packages: scipy, joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-0.17.0 scikit-learn-0.23.2 scipy-1.5.4 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ad/769c195c72ac72040635c66cd9ba7b0f4b4fc1ac67e59b99fa6988446c22/tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4MB 163kB/s  eta 0:00:01     |█████████████████████████████▌  | 295.3MB 52.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/86/753182c9085ba4936c0076269a571613387cdb77ae2bf537448bfd63472c/numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5MB 40.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting pillow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 35.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow) (0.30.0)\n",
      "Collecting google-pasta>=0.1.8 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 32.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
      "Collecting tensorboard<3,>=2.3.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/83/179c8f76e5716030cc3ee9433721161cfcc1d854e9ba20c9205180bb100a/tensorboard-2.4.0-py3-none-any.whl (10.6MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6MB 20.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.24.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
      "Collecting astunparse==1.6.3 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 23.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.12.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 42.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 38.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<3,>=2.3.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/81/67/e2c34bb0628984c7ce71cce6ba6964cb29c418873847fc285f826e032e6e/google_auth_oauthlib-0.4.2-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/60/81e68e70eea91ef05bb00bcdac243d67b61f826c65aaca6961de622dffd7/google_auth-1.23.0-py2.py3-none-any.whl (114kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 49.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779kB)\n",
      "\u001b[K     |████████████████████████████████| 788kB 37.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.16.0)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/fc/f91eac5a39a65f75a7adb58eac7fa78871ea9872283fb9c44e6545998134/requests-2.25.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 28.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\" (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 26.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 45.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/6f/3d85f0850962279a7e4c622695d7b3171e95ac65308a57d3b29738b27149/certifi-2020.11.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 34.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.6)\n",
      "Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 49.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl (136kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 51.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 49.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 32.4MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn, pyyaml\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=2397 sha256=9653514ec5a24acc90576260259a57de4fa5c5dedbb76511a639acca3af52048\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=45919 sha256=cc12928c3af57198bd5ce3b69ac7ace5b473d1a8cf402ce624d0016894a88590\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built sklearn pyyaml\n",
      "\u001b[31mERROR: tensorflow-gpu 2.0.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.0.0 has requirement tensorboard<2.1.0,>=2.0.0, but you'll have tensorboard 2.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.0.0 has requirement tensorflow-estimator<2.1.0,>=2.0.0, but you'll have tensorflow-estimator 2.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.4.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.24.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.3.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, google-pasta, gast, certifi, chardet, urllib3, requests, oauthlib, requests-oauthlib, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, google-auth-oauthlib, tensorboard-plugin-wit, numpy, tensorboard, astunparse, keras-preprocessing, tensorflow-estimator, tensorflow, pyyaml, keras, sklearn, pillow\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: google-pasta 0.1.7\n",
      "    Uninstalling google-pasta-0.1.7:\n",
      "      Successfully uninstalled google-pasta-0.1.7\n",
      "  Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Found existing installation: numpy 1.17.2\n",
      "    Uninstalling numpy-1.17.2:\n",
      "      Successfully uninstalled numpy-1.17.2\n",
      "  Found existing installation: tensorboard 2.0.0\n",
      "    Uninstalling tensorboard-2.0.0:\n",
      "      Successfully uninstalled tensorboard-2.0.0\n",
      "  Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Found existing installation: tensorflow-estimator 2.0.0\n",
      "    Uninstalling tensorflow-estimator-2.0.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.0.0\n",
      "Successfully installed astunparse-1.6.3 cachetools-4.1.1 certifi-2020.11.8 chardet-3.0.4 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 keras-2.4.3 keras-preprocessing-1.1.2 numpy-1.19.4 oauthlib-3.1.0 pillow-8.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyyaml-5.3.1 requests-2.25.0 requests-oauthlib-1.3.0 rsa-4.6 six-1.15.0 sklearn-0.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 urllib3-1.26.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install --upgrade tensorflow keras numpy pandas sklearn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import add\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st round of training: Freeze all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "img_height, img_width = 224, 224\n",
    "filename = \"resnet_freeze_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = ResNet50V2( input_shape=(img_height,img_width,3),\n",
    "                                include_top = False,\n",
    "                                weights = 'imagenet' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make all layers non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1-dimension\n",
    "x = layers.Flatten()(pre_trained_model.output)\n",
    "# Add fully connected layer, with relu activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add dropout\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# Add sigmoid layer for classification. Sigmoid is used instead of softmax, because this is a binary classifier\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "# binary crossentropy used for binary classification\n",
    "model.compile(optimizer=RMSprop(learning_rate),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8500 images belonging to 2 classes.\n",
      "Found 1061 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_directory = \"storage/train\"\n",
    "validation_directory = \"storage/validate\"\n",
    "seed = 10\n",
    "no_epochs = 40\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen =ImageDataGenerator(rescale=1./255,\n",
    "                                 width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_directory, \n",
    "    batch_size = batch_size,\n",
    "    class_mode ='binary',\n",
    "    target_size = (img_height,img_width),\n",
    "shuffle = True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=validation_directory, \n",
    "    class_mode ='binary',\n",
    "    target_size = (img_height,img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.6710 - accuracy: 0.6758 - val_loss: 0.5184 - val_accuracy: 0.7370\n",
      "Epoch 2/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.6086 - accuracy: 0.7131 - val_loss: 0.5046 - val_accuracy: 0.7333\n",
      "Epoch 3/40\n",
      "34/34 [==============================] - 297s 9s/step - loss: 0.5664 - accuracy: 0.7251 - val_loss: 1.0524 - val_accuracy: 0.6032\n",
      "Epoch 4/40\n",
      "34/34 [==============================] - 302s 9s/step - loss: 0.5016 - accuracy: 0.7678 - val_loss: 0.4883 - val_accuracy: 0.7653\n",
      "Epoch 5/40\n",
      "34/34 [==============================] - 296s 9s/step - loss: 0.4813 - accuracy: 0.7759 - val_loss: 0.5640 - val_accuracy: 0.7427\n",
      "Epoch 6/40\n",
      "34/34 [==============================] - 300s 9s/step - loss: 0.4794 - accuracy: 0.7827 - val_loss: 0.3943 - val_accuracy: 0.8143\n",
      "Epoch 7/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.4740 - accuracy: 0.7920 - val_loss: 0.4438 - val_accuracy: 0.7983\n",
      "Epoch 8/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.4303 - accuracy: 0.8035 - val_loss: 0.3938 - val_accuracy: 0.8096\n",
      "Epoch 9/40\n",
      "34/34 [==============================] - 301s 9s/step - loss: 0.3974 - accuracy: 0.8195 - val_loss: 0.4075 - val_accuracy: 0.8134\n",
      "Epoch 10/40\n",
      "34/34 [==============================] - 297s 9s/step - loss: 0.3828 - accuracy: 0.8320 - val_loss: 0.6344 - val_accuracy: 0.7286\n",
      "Epoch 11/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.3726 - accuracy: 0.8342 - val_loss: 0.4406 - val_accuracy: 0.7992\n",
      "Epoch 12/40\n",
      "34/34 [==============================] - 308s 9s/step - loss: 0.3631 - accuracy: 0.8391 - val_loss: 0.4048 - val_accuracy: 0.8181\n",
      "Epoch 13/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.3494 - accuracy: 0.8513 - val_loss: 0.4583 - val_accuracy: 0.8115\n",
      "Epoch 14/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.3262 - accuracy: 0.8568 - val_loss: 0.4078 - val_accuracy: 0.8285\n",
      "Epoch 15/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.3245 - accuracy: 0.8638 - val_loss: 0.4001 - val_accuracy: 0.8238\n",
      "Epoch 16/40\n",
      "34/34 [==============================] - 301s 9s/step - loss: 0.3057 - accuracy: 0.8724 - val_loss: 0.3651 - val_accuracy: 0.8492\n",
      "Epoch 17/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.2960 - accuracy: 0.8740 - val_loss: 0.3866 - val_accuracy: 0.8379\n",
      "Epoch 18/40\n",
      "34/34 [==============================] - 297s 9s/step - loss: 0.3188 - accuracy: 0.8667 - val_loss: 0.4276 - val_accuracy: 0.8143\n",
      "Epoch 19/40\n",
      "34/34 [==============================] - 297s 9s/step - loss: 0.2748 - accuracy: 0.8806 - val_loss: 0.4021 - val_accuracy: 0.8483\n",
      "Epoch 20/40\n",
      "34/34 [==============================] - 300s 9s/step - loss: 0.2838 - accuracy: 0.8776 - val_loss: 0.5153 - val_accuracy: 0.7974\n",
      "Epoch 21/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.2674 - accuracy: 0.8900 - val_loss: 0.8846 - val_accuracy: 0.7041\n",
      "Epoch 22/40\n",
      "34/34 [==============================] - 308s 9s/step - loss: 0.2513 - accuracy: 0.8966 - val_loss: 0.3847 - val_accuracy: 0.8615\n",
      "Epoch 23/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.2752 - accuracy: 0.8882 - val_loss: 0.4185 - val_accuracy: 0.8549\n",
      "Epoch 24/40\n",
      "34/34 [==============================] - 300s 9s/step - loss: 0.2583 - accuracy: 0.8906 - val_loss: 0.3777 - val_accuracy: 0.8473\n",
      "Epoch 25/40\n",
      "34/34 [==============================] - 301s 9s/step - loss: 0.2356 - accuracy: 0.9024 - val_loss: 0.4233 - val_accuracy: 0.8454\n",
      "Epoch 26/40\n",
      "34/34 [==============================] - 300s 9s/step - loss: 0.2222 - accuracy: 0.9100 - val_loss: 0.3890 - val_accuracy: 0.8652\n",
      "Epoch 27/40\n",
      "34/34 [==============================] - 306s 9s/step - loss: 0.2232 - accuracy: 0.9101 - val_loss: 0.4009 - val_accuracy: 0.8586\n",
      "Epoch 28/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.2291 - accuracy: 0.9094 - val_loss: 0.4540 - val_accuracy: 0.8303\n",
      "Epoch 29/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.2125 - accuracy: 0.9162 - val_loss: 0.4520 - val_accuracy: 0.8332\n",
      "Epoch 30/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.2247 - accuracy: 0.9162 - val_loss: 0.9590 - val_accuracy: 0.6956\n",
      "Epoch 31/40\n",
      "34/34 [==============================] - 307s 9s/step - loss: 0.1821 - accuracy: 0.9274 - val_loss: 0.3705 - val_accuracy: 0.8605\n",
      "Epoch 32/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.1799 - accuracy: 0.9267 - val_loss: 0.3832 - val_accuracy: 0.8596\n",
      "Epoch 33/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.2020 - accuracy: 0.9231 - val_loss: 0.4414 - val_accuracy: 0.8464\n",
      "Epoch 34/40\n",
      "34/34 [==============================] - 300s 9s/step - loss: 0.1780 - accuracy: 0.9280 - val_loss: 0.4120 - val_accuracy: 0.8558\n",
      "Epoch 35/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.1951 - accuracy: 0.9231 - val_loss: 0.4300 - val_accuracy: 0.8483\n",
      "Epoch 36/40\n",
      "34/34 [==============================] - 301s 9s/step - loss: 0.1872 - accuracy: 0.9267 - val_loss: 0.4439 - val_accuracy: 0.8605\n",
      "Epoch 37/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.1638 - accuracy: 0.9388 - val_loss: 0.4960 - val_accuracy: 0.8407\n",
      "Epoch 38/40\n",
      "34/34 [==============================] - 299s 9s/step - loss: 0.1718 - accuracy: 0.9336 - val_loss: 0.4844 - val_accuracy: 0.8577\n",
      "Epoch 39/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.1642 - accuracy: 0.9368 - val_loss: 1.0032 - val_accuracy: 0.7597\n",
      "Epoch 40/40\n",
      "34/34 [==============================] - 298s 9s/step - loss: 0.1687 - accuracy: 0.9349 - val_loss: 0.6098 - val_accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = f\"storage/checkpoint/{filename}.hdf5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator, \n",
    "                    epochs=no_epochs, \n",
    "                    verbose=1,\n",
    "                   callbacks=[model_checkpoint_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss= history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(f'storage/results/{filename}_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(f'storage/results/{filename}_loss.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(f\"storage/checkpoint/{filename}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1635 images belonging to 2 classes.\n",
      "103/103 [==============================] - 45s 433ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_directory = \"storage/test/\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = test_datagen.flow_from_directory(\n",
    "        test_directory,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels\n",
    "\n",
    "probabilities = model.predict_generator(generator, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_female = sum(len(files) for _, _, files in os.walk('storage/test/female'))\n",
    "num_male = sum(len(files) for _, _, files in os.walk('storage/test/male'))\n",
    "print(num_female + num_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[785 101]\n",
      " [105 644]]\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([0] * num_female + [1] * num_male)\n",
    "y_pred = probabilities > 0.5\n",
    "\n",
    "res = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(res, cmap='Blues')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = ax.text(j, i, res[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"y\")\n",
    "plt.title('Confusion matrix from model prediction')\n",
    "plt.savefig(f'storage/results/{filename}_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd round of training: Unfreeze last block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "img_height, img_width = 224, 224\n",
    "filename = \"resnet_fine_tune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = ResNet50V2( input_shape=(img_height,img_width,3),\n",
    "                                include_top = False,\n",
    "                                weights = 'imagenet'        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze last 38 layers\n",
    "for layer in pre_trained_model.layers[:-38]:\n",
    "    layer.trainable= False\n",
    "for layer in pre_trained_model.layers[-38:]:\n",
    "    layer.trainable= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1-dimension\n",
    "x = layers.Flatten()(pre_trained_model.output)\n",
    "# Add fully connected layer, with relu activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add dropout\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# Add sigmoid layer for classification. Sigmoid is used instead of softmax, because this is a binary classifier\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "# binary crossentropy used for binary classification\n",
    "model.compile(optimizer=RMSprop(learning_rate),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up train and validation generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8500 images belonging to 2 classes.\n",
      "Found 1061 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_directory = \"storage/train\"\n",
    "validation_directory = \"storage/validate\"\n",
    "seed = 10\n",
    "no_epochs = 40\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen =ImageDataGenerator(rescale=1./255,\n",
    "                                 width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_directory, \n",
    "    batch_size = batch_size,\n",
    "    class_mode ='binary',\n",
    "    target_size = (img_height,img_width),\n",
    "shuffle = True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=validation_directory, \n",
    "    class_mode ='binary',\n",
    "    target_size = (img_height,img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-6fef6074902e>:16: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/40\n",
      "34/34 [==============================] - 486s 14s/step - loss: 1.5426 - accuracy: 0.7412 - val_loss: 0.7147 - val_accuracy: 0.7418\n",
      "Epoch 2/40\n",
      "34/34 [==============================] - 479s 14s/step - loss: 0.3422 - accuracy: 0.8505 - val_loss: 0.3803 - val_accuracy: 0.8699\n",
      "Epoch 3/40\n",
      "34/34 [==============================] - 482s 14s/step - loss: 0.2083 - accuracy: 0.9139 - val_loss: 0.4254 - val_accuracy: 0.8954\n",
      "Epoch 4/40\n",
      "34/34 [==============================] - 480s 14s/step - loss: 0.1555 - accuracy: 0.9369 - val_loss: 0.5016 - val_accuracy: 0.9029\n",
      "Epoch 5/40\n",
      "34/34 [==============================] - 482s 14s/step - loss: 0.1013 - accuracy: 0.9605 - val_loss: 0.5575 - val_accuracy: 0.9171\n",
      "Epoch 6/40\n",
      "34/34 [==============================] - 478s 14s/step - loss: 0.0787 - accuracy: 0.9721 - val_loss: 0.8274 - val_accuracy: 0.8869\n",
      "Epoch 7/40\n",
      "34/34 [==============================] - 481s 14s/step - loss: 0.0698 - accuracy: 0.9754 - val_loss: 0.6805 - val_accuracy: 0.9189\n",
      "Epoch 8/40\n",
      "34/34 [==============================] - 477s 14s/step - loss: 0.0451 - accuracy: 0.9816 - val_loss: 0.9468 - val_accuracy: 0.9152\n",
      "Epoch 9/40\n",
      "34/34 [==============================] - 479s 14s/step - loss: 0.0467 - accuracy: 0.9845 - val_loss: 2.0365 - val_accuracy: 0.8530\n",
      "Epoch 10/40\n",
      "34/34 [==============================] - 478s 14s/step - loss: 0.0418 - accuracy: 0.9874 - val_loss: 0.9081 - val_accuracy: 0.9208\n",
      "Epoch 11/40\n",
      "34/34 [==============================] - 482s 14s/step - loss: 0.0361 - accuracy: 0.9865 - val_loss: 0.8641 - val_accuracy: 0.9171\n",
      "Epoch 12/40\n",
      "34/34 [==============================] - 490s 14s/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 2.0235 - val_accuracy: 0.8615\n",
      "Epoch 13/40\n",
      "34/34 [==============================] - 479s 14s/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.9712 - val_accuracy: 0.9255\n",
      "Epoch 14/40\n",
      "34/34 [==============================] - 481s 14s/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 1.0649 - val_accuracy: 0.9350\n",
      "Epoch 15/40\n",
      "34/34 [==============================] - 477s 14s/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 1.1025 - val_accuracy: 0.9321\n",
      "Epoch 16/40\n",
      "34/34 [==============================] - 479s 14s/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 1.2039 - val_accuracy: 0.9227\n",
      "Epoch 17/40\n",
      "34/34 [==============================] - 474s 14s/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 1.1273 - val_accuracy: 0.9265\n",
      "Epoch 18/40\n",
      "34/34 [==============================] - 481s 14s/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 1.2307 - val_accuracy: 0.9321\n",
      "Epoch 19/40\n",
      "34/34 [==============================] - 481s 14s/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 1.6167 - val_accuracy: 0.9057\n",
      "Epoch 20/40\n",
      "34/34 [==============================] - 477s 14s/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 1.7545 - val_accuracy: 0.9312\n",
      "Epoch 21/40\n",
      "34/34 [==============================] - 475s 14s/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 5.1164 - val_accuracy: 0.8369\n",
      "Epoch 22/40\n",
      "34/34 [==============================] - 482s 14s/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 6.3033 - val_accuracy: 0.8011\n",
      "Epoch 23/40\n",
      "34/34 [==============================] - 476s 14s/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 4.1839 - val_accuracy: 0.8341\n",
      "Epoch 24/40\n",
      "34/34 [==============================] - 476s 14s/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 4.8803 - val_accuracy: 0.8388\n",
      "Epoch 25/40\n",
      "34/34 [==============================] - 482s 14s/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 2.2289 - val_accuracy: 0.9029\n",
      "Epoch 26/40\n",
      "34/34 [==============================] - 478s 14s/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 3.8969 - val_accuracy: 0.8662\n",
      "Epoch 27/40\n",
      "34/34 [==============================] - 477s 14s/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 1.6730 - val_accuracy: 0.9331\n",
      "Epoch 28/40\n",
      "34/34 [==============================] - 479s 14s/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 1.8876 - val_accuracy: 0.9180\n",
      "Epoch 29/40\n",
      "34/34 [==============================] - 476s 14s/step - loss: 0.0200 - accuracy: 0.9958 - val_loss: 2.2752 - val_accuracy: 0.9321\n",
      "Epoch 30/40\n",
      "34/34 [==============================] - 480s 14s/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 1.9057 - val_accuracy: 0.9171\n",
      "Epoch 31/40\n",
      "34/34 [==============================] - 478s 14s/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 2.4382 - val_accuracy: 0.9189\n",
      "Epoch 32/40\n",
      "34/34 [==============================] - 476s 14s/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 1.6500 - val_accuracy: 0.9218\n",
      "Epoch 33/40\n",
      "34/34 [==============================] - 478s 14s/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 2.1229 - val_accuracy: 0.9246\n",
      "Epoch 34/40\n",
      "34/34 [==============================] - 477s 14s/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 4.1569 - val_accuracy: 0.8944\n",
      "Epoch 35/40\n",
      "34/34 [==============================] - 478s 14s/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 2.8822 - val_accuracy: 0.9161\n",
      "Epoch 36/40\n",
      "34/34 [==============================] - 478s 14s/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 2.0948 - val_accuracy: 0.9331\n",
      "Epoch 37/40\n",
      "34/34 [==============================] - 480s 14s/step - loss: 0.0222 - accuracy: 0.9954 - val_loss: 7.9616 - val_accuracy: 0.8756\n",
      "Epoch 38/40\n",
      "34/34 [==============================] - 479s 14s/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 3.5022 - val_accuracy: 0.9284\n",
      "Epoch 39/40\n",
      "34/34 [==============================] - 479s 14s/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 3.0263 - val_accuracy: 0.9152\n",
      "Epoch 40/40\n",
      "34/34 [==============================] - 482s 14s/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 3.8399 - val_accuracy: 0.9171\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = f\"storage/checkpoint/{filename}.hdf5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator, \n",
    "                    epochs=no_epochs, \n",
    "                    verbose=1,\n",
    "                   callbacks=[model_checkpoint_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss= history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(f'storage/results/{filename}_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(f'storage/results/{filename}_loss.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "model.load_weights(f\"storage/checkpoint/{filename}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1635 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From <ipython-input-14-7767c4b5b2b0>:14: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "103/103 [==============================] - 40s 388ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_directory = \"storage/test/\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = test_datagen.flow_from_directory(\n",
    "        test_directory,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels\n",
    "\n",
    "probabilities = model.predict_generator(generator, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_female = sum(len(files) for _, _, files in os.walk('storage/test/female'))\n",
    "num_male = sum(len(files) for _, _, files in os.walk('storage/test/male'))\n",
    "print(num_female + num_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[835  51]\n",
      " [ 73 676]]\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([0] * num_female + [1] * num_male)\n",
    "y_pred = probabilities > 0.5\n",
    "\n",
    "res = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(res, cmap='Blues')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = ax.text(j, i, res[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"y\")\n",
    "plt.title('Confusion matrix from model prediction')\n",
    "plt.savefig(f'storage/results/{filename}_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
